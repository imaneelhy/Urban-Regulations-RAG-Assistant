# -*- coding: utf-8 -*-
"""qa.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16KDTWvry68c9SDPvoIGqL7mLLZcWdwUb
"""

from typing import List, Dict
import os

from langchain.schema import Document
from langchain_openai import ChatOpenAI

from src.config import OPENAI_API_KEY, OPENAI_MODEL_NAME
from src.rag.retriever import UrbanRegulationsRetriever

SYSTEM_PROMPT = """
You are an assistant specialized in URBAN PLANNING REGULATIONS.

You receive:
- a user question about zoning/building/permits
- a set of context excerpts from official regulations

Your tasks:
1. Answer the question STRICTLY based on the provided context.
2. Cite the relevant sources explicitly, e.g. (Source: {source_file}, page {page}).
3. If the answer is not in the context, say you do not know and suggest where the user might look.

Be clear and concise, but keep legal/technical terms accurate.
"""


class UrbanRegulationsQA:
    def __init__(self, k: int = 5):
        if not OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY is not set in the environment.")
        self.retriever = UrbanRegulationsRetriever(k=k)
        self.llm = ChatOpenAI(
            model=OPENAI_MODEL_NAME,
            temperature=0.1,
            api_key=OPENAI_API_KEY,
        )

    @staticmethod
    def _format_context(docs: List[Document]) -> str:
        formatted_chunks = []
        for i, d in enumerate(docs, start=1):
            meta = d.metadata or {}
            source = meta.get("source_file", meta.get("source", "unknown"))
            page = meta.get("page", "N/A")
            formatted_chunks.append(
                f"[Chunk {i}] (Source: {source}, page {page})\n{d.page_content}"
            )
        return "\n\n".join(formatted_chunks)

    def answer(self, question: str) -> Dict:
        docs = self.retriever.retrieve(question)
        context = self._format_context(docs)

        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {
                "role": "user",
                "content": (
                    f"Question: {question}\n\n"
                    f"Context documents:\n{context}\n\n"
                    "Now provide a detailed answer with citations."
                ),
            },
        ]

        response = self.llm.invoke(messages)
        answer_text = response.content

        sources = []
        for d in docs:
            meta = d.metadata or {}
            sources.append(
                {
                    "source_file": meta.get("source_file", meta.get("source", "unknown")),
                    "page": meta.get("page", None),
                    "section": meta.get("section", None),
                }
            )

        return {"answer": answer_text, "sources": sources}